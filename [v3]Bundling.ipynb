{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded auctions file with auction_id to location mapping.\n",
      "Created pickupdates dictionary for pickupdate to auction_ID mapping.\n",
      "Created pickupdates dictionary for auction_ID to pickupdate mapping.\n",
      "Processing files in the BIDFTA folder:\n",
      "\n",
      "--- Processing '000002.csv' ---\n",
      "\n",
      "--- Processing '000003.csv' ---\n",
      "\n",
      "--- Processing '000004.csv' ---\n",
      "\n",
      "--- Processing '000005.csv' ---\n",
      "\n",
      "--- Processing '000006.csv' ---\n",
      "\n",
      "--- Processing '000007.csv' ---\n",
      "\n",
      "--- Processing '000008.csv' ---\n",
      "\n",
      "--- Processing '000009.csv' ---\n",
      "\n",
      "--- Processing '000010.csv' ---\n",
      "\n",
      "--- Processing '000011.csv' ---\n",
      "\n",
      "Data successfully saved as CSV at 'C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\02_filtered\\UPDATED.csv'\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder\n",
    "folder_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\02_filtered\\items\" #Defines folder_path, a string with the path to the folder containing files to be processed. The r before the string indicates a raw string to treat backslashes \\ as literal characters.\n",
    "auction_location_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\auctions-dataset-filtered-auctions\\auctions\\auctions.csv\"\n",
    "location_info_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\auctions-dataset-filtered-auctions\\auctions_data\\auctions_locations.csv\"\n",
    "pickupdates_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\auctions-dataset-filtered-auctions\\auctions_data\\auctions_pickupdates.csv\"\n",
    "\n",
    "# Initialize an empty list to store rows of item details directly\n",
    "data = []\n",
    "\n",
    "# Load the auctions file containing auction_id to location mapping\n",
    "try:\n",
    "    auctions_df = pd.read_csv(auction_location_path)\n",
    "    print(\"Loaded auctions file with auction_id to location mapping.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the auctions file: {e}\")\n",
    "\n",
    "\n",
    "# Create a dictionary mapping auction_id (ID) to location_ID\n",
    "location_dict = {}\n",
    "try:\n",
    "    auctions_df = pd.read_csv(auction_location_path, delimiter='\\t', usecols=[\"ID\", \"location_ID\"])\n",
    "    auctions_df['ID'] = auctions_df['ID'].astype(str)  # Ensure ID is a string for consistency\n",
    "    \n",
    "    # Create a dictionary mapping auction_id (ID) to location_ID\n",
    "    location_dict = dict(zip(auctions_df['ID'], auctions_df['location_ID']))\n",
    "    location_dict\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the auctions file: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Create a dictionary for location details using location_ID as the key\n",
    "location_info_dict = {}\n",
    "try:\n",
    "    location_info_df = pd.read_csv(location_info_path, delimiter='\\t', usecols=[\"id\", \"state\", \"zip\",\"tzoffset_utc\",\"tzoffset_et\"])\n",
    "    location_info_df['id'] = location_info_df['id'].astype(str)  # Ensure location_ID (id) is a string\n",
    "    location_info_df['zip'] = location_info_df['zip'].astype(str)  # Ensure zip is stored as string\n",
    "    \n",
    "    # Populate location_info_dict with location_ID as key and (state, zip, tzoffset_utc, tzoffset_et) as values\n",
    "    location_info_dict = location_info_df.set_index('id')[['state', 'zip']].to_dict(orient='index')\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading location info file: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Create a dictionary for pickupdates as key and auction ID as value\n",
    "auctionsID_dict = {}\n",
    "try:\n",
    "    auctionsID_df = pd.read_csv(pickupdates_path, delimiter='\\t', usecols=[\"auction_ID\",\"date\"])\n",
    "    auctionsID_df['date'] = auctionsID_df['date'].astype(str)\n",
    "    \n",
    "    # Populate auctionsID_dict with pickupdates as key and a list of auction_ID as values\n",
    "    for _, row in auctionsID_df.iterrows():\n",
    "        auction_id = row['auction_ID']\n",
    "        pickupdate = row['date']\n",
    "        if pickupdate in auctionsID_dict:\n",
    "            auctionsID_dict[pickupdate].append(auction_id)\n",
    "        else:\n",
    "            auctionsID_dict[pickupdate] = [auction_id]\n",
    "    print(\"Created pickupdates dictionary for pickupdate to auction_ID mapping.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading pickupdates file: {e}\")\n",
    "\n",
    "\n",
    "# Create a dictionary for pickupdates using pickupdates_path\n",
    "pickupdates_dict = {}\n",
    "try:\n",
    "    pickupdates_df = pd.read_csv(pickupdates_path, delimiter='\\t', usecols=[\"auction_ID\", \"date\"])\n",
    "    pickupdates_df['auction_ID'] = pickupdates_df['auction_ID'].astype(str)  # Ensure auction_ID is a string\n",
    "    \n",
    "    # Populate pickupdates_dict with auction_ID as key and a list of pickupdate as values\n",
    "    for _, row in pickupdates_df.iterrows():\n",
    "        auction_id = row['auction_ID']\n",
    "        pickupdate = row['date']\n",
    "        if auction_id in pickupdates_dict:\n",
    "            pickupdates_dict[auction_id].append(pickupdate)\n",
    "        else:\n",
    "            pickupdates_dict[auction_id] = [pickupdate]\n",
    "    print(\"Created pickupdates dictionary for auction_ID to pickupdate mapping.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading pickupdates file: {e}\")\n",
    "\n",
    "\n",
    "# Create a nested dictionary for auction, location and pickupdates\n",
    "auction_location_pickupdates = {}\n",
    "try:\n",
    "    for auction_id, location_id in location_dict.items():\n",
    "        if auction_id in pickupdates_dict:\n",
    "            pickupdates = pickupdates_dict[auction_id]\n",
    "            if auction_id not in auction_location_pickupdates:\n",
    "                auction_location_pickupdates[auction_id] = {}\n",
    "            auction_location_pickupdates[auction_id][location_id] = pickupdates\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while building the nested dictionary: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MAIN\n",
    "try:\n",
    "    files = os.listdir(folder_path) [:10]  #Uses os.listdir to retrieve a list of all entries (files/folders) in the specified directory.\n",
    "    print(\"Processing files in the BIDFTA folder:\")\n",
    "\n",
    "    for file_name in files: #Starts a loop through each file_name in files\n",
    "        file_path = os.path.join(folder_path, file_name) #Constructs the full path to each file by combining folder_path and file_name\n",
    "        \n",
    "        #Checks if file_path is a file (not a folder) with os.path.isfile. If it is a file, prints a message stating which file is currently being processed:\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"\\n--- Processing '{file_name}' ---\")\n",
    "            try:\n",
    "           \n",
    "                with open(file_path, 'r') as file: #Opens the file in read mode\n",
    "                    for line_number, line in enumerate(file, start=1): #Loops through each line in the file, with enumerate providing the line number, starting from 1.\n",
    "                     \n",
    "                        row_data = line.strip().split('\\t') #Strips whitespace from the line and splits it by the tab character ('\\t'), storing the resulting list of values in row_data.\n",
    "                      \n",
    "                        if line_number==1:\n",
    "                            continue\n",
    "\n",
    "                        #Extracts product_id from the fifth element and msrp_value from the twelfth element of row_data.\n",
    "                        AUCTION_ID = row_data[0]\n",
    "                        ITEM_ID = row_data[1]  \n",
    "                        BIDDER_ID = row_data[12] \n",
    "\n",
    "    \n",
    "\n",
    "                        # Look up location_ID from location_dict\n",
    "                        LOCATION_ID = location_dict.get(AUCTION_ID, None)\n",
    "\n",
    "                        \n",
    "\n",
    "                        # Append item details including location_id, state, and zip to `data`\n",
    "                        data.append([AUCTION_ID, LOCATION_ID, ITEM_ID, BIDDER_ID ])\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while reading '{file_name}': {e}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"The folder '{folder_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Create DataFrame with headers including location_id, state, and zip\n",
    "df = pd.DataFrame(data, columns=[\"AUCTION_ID\", \"LOCATION_ID\", \"ITEM_ID\", \"BIDDER_ID\"])\n",
    "\n",
    "# Ensure user_id is treated as a string and handle empty values\n",
    "df['BIDDER_ID'] = df['BIDDER_ID'].astype(str).replace('', None)\n",
    "\n",
    "# Add the new column: \"other items in auction\"\n",
    "df['ITEMS_WON_IN_AUCTION'] = (\n",
    "    df[df['BIDDER_ID'].notna()]  # Exclude rows with empty user_id\n",
    "    .groupby(['AUCTION_ID', 'BIDDER_ID'])['BIDDER_ID']\n",
    "    .transform('size') \n",
    ")\n",
    "\n",
    "# Fill NaN for rows where user_id is empty with 0\n",
    "df['ITEMS_WON_IN_AUCTION'] = df['ITEMS_WON_IN_AUCTION'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Define the path for saving the output as CSV\n",
    "csv_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\02_filtered\\UPDATED.csv\"\n",
    "try:\n",
    "    df.to_csv(csv_path, index=False)  # Save as CSV without the index\n",
    "    print(f\"\\nData successfully saved as CSV at '{csv_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving CSV: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
