{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bundling data successfully saved to C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\02_filtered\\bundling_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the paths\n",
    "folder_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\02_filtered\\items\"\n",
    "auction_location_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\auctions-dataset-filtered-auctions\\auctions\\auctions.csv\"\n",
    "location_info_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\auctions-dataset-filtered-auctions\\auctions_data\\auctions_locations.csv\"\n",
    "pickupdates_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\auctions-dataset-filtered-auctions\\auctions_data\\auctions_pickupdates.csv\"\n",
    "\n",
    "# Initialize dictionaries\n",
    "location_dict = {}\n",
    "auctionsID_dict = {}\n",
    "pickupdates_dict = {}\n",
    "\n",
    "# Load the auctions file to map auction_id to location_ID\n",
    "try:\n",
    "    auctions_df = pd.read_csv(auction_location_path, delimiter='\\t', usecols=[\"ID\", \"location_ID\"])\n",
    "    auctions_df['ID'] = auctions_df['ID'].astype(str)\n",
    "    location_dict = dict(zip(auctions_df['ID'], auctions_df['location_ID']))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading auctions file: {e}\")\n",
    "\n",
    "# Load pickup dates and create mappings\n",
    "try:\n",
    "    auctionsID_df = pd.read_csv(pickupdates_path, delimiter='\\t', usecols=[\"auction_ID\", \"date\"])\n",
    "    auctionsID_df['auction_ID'] = auctionsID_df['auction_ID'].astype(str)\n",
    "    auctionsID_dict = auctionsID_df.groupby('date')['auction_ID'].apply(list).to_dict()\n",
    "    pickupdates_dict = auctionsID_df.groupby('auction_ID')['date'].apply(list).to_dict()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading pickup dates file: {e}\")\n",
    "\n",
    "# Process files in the items folder\n",
    "bundling_data = []\n",
    "\n",
    "try:\n",
    "    files = os.listdir(folder_path)[:100]\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    for line_number, line in enumerate(file, start=1):\n",
    "                        if line_number == 1:\n",
    "                            continue\n",
    "                        row_data = line.strip().split('\\t')\n",
    "                        auction_id, item_id, user_id = row_data[0], row_data[1], row_data[12]\n",
    "\n",
    "                        # Retrieve the pickup date for the auction\n",
    "                        pickup_dates = pickupdates_dict.get(auction_id, [])\n",
    "                        for pickup_date in pickup_dates:\n",
    "                            # Retrieve auctions with the same pickup date\n",
    "                            same_pickup_auctions = auctionsID_dict.get(pickup_date, [])\n",
    "                            for same_auction_id in same_pickup_auctions:\n",
    "                                # Check if the auction locations match\n",
    "                                if location_dict.get(auction_id) == location_dict.get(same_auction_id):\n",
    "                                    # Open the items file for the matching auction\n",
    "                                    same_auction_file_path = os.path.join(folder_path, f\"{same_auction_id}.csv\")\n",
    "                                    if os.path.isfile(same_auction_file_path):\n",
    "                                        try:\n",
    "                                            same_auction_items_df = pd.read_csv(same_auction_file_path, delimiter='\\t')\n",
    "                                            same_auction_items_df['user_id'] = same_auction_items_df['user_id'].astype(str)\n",
    "                                            bundling_count = same_auction_items_df['user_id'].value_counts().to_dict()\n",
    "\n",
    "                                            # Add bundling count for the current item\n",
    "                                            bundling_data.append({\n",
    "                                                \"Auction_ID\": auction_id,\n",
    "                                                \"Item_ID\": item_id,\n",
    "                                                \"User_ID\": user_id,\n",
    "                                                \"Pickup_Date\": pickup_date,\n",
    "                                                \"Bundling_Count\": bundling_count.get(user_id, 0)\n",
    "                                            })\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"Error processing items for auction {same_auction_id}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_name}: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing folder: {e}\")\n",
    "\n",
    "# Convert bundling data to a DataFrame\n",
    "bundling_df = pd.DataFrame(bundling_data)\n",
    "\n",
    "# Save results\n",
    "output_path = r\"C:\\Users\\mydoa\\Desktop\\BIDFTA DATASET\\auctions-dataset\\tools\\nodejs-dataset-downloader\\02_filtered\\bundling_results.csv\"\n",
    "try:\n",
    "    bundling_df.to_csv(output_path, index=False)\n",
    "    print(f\"Bundling data successfully saved to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving bundling results CSV: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '99',\n",
       " '101',\n",
       " '102',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '109',\n",
       " '110',\n",
       " '111',\n",
       " '112',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '118',\n",
       " '119',\n",
       " '120',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '124',\n",
       " '125',\n",
       " '126',\n",
       " '127',\n",
       " '128',\n",
       " '129',\n",
       " '130',\n",
       " '131',\n",
       " '132',\n",
       " '139',\n",
       " '140',\n",
       " '141',\n",
       " '142',\n",
       " '143',\n",
       " '144',\n",
       " '146',\n",
       " '147',\n",
       " '148',\n",
       " '149',\n",
       " '150',\n",
       " '152',\n",
       " '153',\n",
       " '155',\n",
       " '156',\n",
       " '160',\n",
       " '161',\n",
       " '162',\n",
       " '163',\n",
       " '169',\n",
       " '170',\n",
       " '171',\n",
       " '172',\n",
       " '174',\n",
       " '177',\n",
       " '181',\n",
       " '187']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auctions_with_same_pickup_dates "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
